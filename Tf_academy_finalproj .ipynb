{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Capstone Project: Sentiment Analysis using Image & Text Data**"
      ],
      "metadata": {
        "id": "opDx9l8ZyRhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "id": "uDoRKcNyyXMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Data Preprocessing**"
      ],
      "metadata": {
        "id": "n8fnZAB1yis4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text  **Data Preprocessing**"
      ],
      "metadata": {
        "id": "b5GgAVJGyxRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Data Preprocessing\n",
        "def preprocess_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    words = word_tokenize(text)\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "text_data = pd.read_csv('text_data.csv')\n",
        "text_data['cleaned_text'] = text_data['text_column'].apply(preprocess_text)\n",
        "\n",
        "# Tokenization\n",
        "max_words = 5000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(text_data['cleaned_text'])\n",
        "sequences = tokenizer.texts_to_sequences(text_data['cleaned_text'])\n",
        "text_padded = pad_sequences(sequences, maxlen=100)\n"
      ],
      "metadata": {
        "id": "dab7z2bEyuA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Data Preprocessing**"
      ],
      "metadata": {
        "id": "FuGuOgjMzWTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Data Preprocessing\n",
        "image_dir = 'image_dataset/'\n",
        "image_data = []\n",
        "labels = []\n",
        "label_map = {\"positive\": 0, \"negative\": 1, \"neutral\": 2}\n",
        "\n",
        "for label in os.listdir(image_dir):\n",
        "    for image_file in os.listdir(os.path.join(image_dir, label)):\n",
        "        img_path = os.path.join(image_dir, label, image_file)\n",
        "        img = load_img(img_path, target_size=(128, 128))\n",
        "        img_array = img_to_array(img) / 255.0\n",
        "        image_data.append(img_array)\n",
        "        labels.append(label_map[label])\n",
        "\n",
        "image_data = np.array(image_data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# data split\n",
        "X_train_img, X_test_img, y_train_img, y_test_img = train_test_split(image_data, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "sbejqZuOzbwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Architecture**"
      ],
      "metadata": {
        "id": "KhDyg3MXz9_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN Model for Images**"
      ],
      "metadata": {
        "id": "omgbRoXC0Ejg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Model for Image Sentiment Analysis\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.summary()\n",
        "\n",
        "# Train cnn model\n",
        "cnn_history = cnn_model.fit(X_train_img, y_train_img, validation_split=0.2, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "y7Q-SReZz9aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN Model for Text**"
      ],
      "metadata": {
        "id": "PpjqHbj20b1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN Model for Text Sentiment Analysis\n",
        "rnn_model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=128, input_length=100),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(64),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "rnn_model.summary()\n",
        "\n",
        "# Train RNN Model\n",
        "text_labels = text_data['label_column'].map(label_map).values\n",
        "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(text_padded, text_labels, test_size=0.2, random_state=42)\n",
        "rnn_history = rnn_model.fit(X_train_text, y_train_text, validation_split=0.2, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "VXmWppAl0dmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**"
      ],
      "metadata": {
        "id": "0DuzXEZV0vmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics for CNN\n",
        "y_pred_img = np.argmax(cnn_model.predict(X_test_img), axis=1)\n",
        "print(\"Confusion Matrix for Images:\")\n",
        "print(confusion_matrix(y_test_img, y_pred_img))\n",
        "print(\"Classification Report for Images:\")\n",
        "print(classification_report(y_test_img, y_pred_img))\n"
      ],
      "metadata": {
        "id": "SQf02H9q0x8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics for RNN\n",
        "y_pred_text = np.argmax(rnn_model.predict(X_test_text), axis=1)\n",
        "print(\"Confusion Matrix for Text:\")\n",
        "print(confusion_matrix(y_test_text, y_pred_text))\n",
        "print(\"Classification Report for Text:\")\n",
        "print(classification_report(y_test_text, y_pred_text))\n"
      ],
      "metadata": {
        "id": "fA0dd79o08Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Saving Models"
      ],
      "metadata": {
        "id": "Et4MFStw1AIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Trained Models\n",
        "cnn_model.save('cnn_sentiment_model')\n",
        "rnn_model.save('rnn_sentiment_model')\n"
      ],
      "metadata": {
        "id": "XN-eDwpt1F-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}